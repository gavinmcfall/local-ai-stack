model_list:

# --------------------------------------------
# ---------- Locally Hosted Models -----------
# --------------------------------------------

  # Note: Cold start on these models can take upwards of 15s, after which they perform well.

  # ğŸ§  LOCAL CHAT MODEL - Great for general conversation and dev experiments
  - model_name: ollama/llama3:8b
    litellm_params:
      model: ollama/llama3:8b
      api_base: http://host.docker.internal:11434 # MacOS or Windows
    # api_base: http://<your-host-IP>:11434 # Linux
    model_info:
      id: ollama/llama3:8b
      mode: completion
      max_tokens: 8192 # Estimated context window for 8B models

  # ğŸ” LOCAL EMBEDDING MODEL - For semantic search, RAG, and vector indexing
  - model_name: ollama/nomic-embed-text
    litellm_params:
      model: ollama/nomic-embed-text
      api_base: http://host.docker.internal:11434 # MacOS or Windows
    # api_base: http://<your-host-IP>:11434 # Linux
    model_info:
      id: ollama/nomic-embed-text
      mode: embedding
      max_tokens: 512 # Conservative estimate

# --------------------------------------------
# ------------ AWS Bedrock Models ------------
# --------------------------------------------


  # ğŸ¤– CHAT â€‘ ClaudeÂ 3Â Sonnet (balanced)
  - model_name: Bedrock Â· Claude 3 Sonnet
    litellm_params:
      model: "bedrock/anthropic.claude-3-sonnet-20240229-v1:0"
    model_info:
      id: anthropic.claude-3-sonnet-20240229-v1:0
      mode: completion
      input_cost_per_token: 0.000003     # $0.003â€¯/â€¯1â€¯000
      output_cost_per_token: 0.000015    # $0.015â€¯/â€¯1â€¯000
      max_tokens: 200000

  # ğŸ§  CHAT â€‘ ClaudeÂ 3.5Â SonnetÂ v2 (premium)
  - model_name: Bedrock Â· Claude 3.5 Sonnet v2
    litellm_params:
      model: "bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0"
    model_info:
      id: anthropic.claude-3-5-sonnet-20241022-v2:0
      mode: completion
      input_cost_per_token: 0.000003     # $0.003â€¯/â€¯1â€¯000
      output_cost_per_token: 0.000015    # $0.015â€¯/â€¯1â€¯000
      max_tokens: 200000

  # ğŸ’¬ CHAT â€‘ MixtralÂ 8Ã—7BÂ Instruct
  - model_name: Bedrock Â· Mixtral 8x7B Instruct
    provider: bedrock
    litellm_params:
      model: bedrock/mistral.mixtral-8x7b-instruct-v0:1
    model_info:
      id: mistral.mixtral-8x7b-instruct-v0:1
      mode: completion
      input_cost_per_token:  0.00000045   # $0.00045â€¯/â€¯1â€¯000
      output_cost_per_token: 0.00000070   # $0.00070â€¯/â€¯1â€¯000
      max_tokens: 32000

  # ğŸ‡¬ğŸ‡§ EMBEDDING â€‘ English
  - model_name: Bedrock Â· Embed English (base)
    provider: bedrock
    litellm_params:
      model: bedrock/cohere.embed-english-v3
    model_info:
      id: cohere.embed-english-v3
      mode: embedding
      input_cost_per_token: 0.00000010  # $0.00010â€¯/â€¯1â€¯000
      output_cost_per_token: 0  # Embeds are input only
      max_tokens: 512

  # ğŸŒ EMBEDDING â€‘ Multilingual
  - model_name: Bedrock Â· Embed Multilingual (base)
    provider: bedrock
    litellm_params:
      model: cohere.embed-multilingual-v3
    model_info:
      id: cohere.embed-multilingual-v3
      mode: embedding
      input_cost_per_token: 0.00000010  # $0.00010â€¯/â€¯1â€¯000
      output_cost_per_token: 0  # Embeds are input only
      max_tokens: 512

  # ğŸ”Š TTS â€‘ NovaÂ Sonic
  - model_name: Bedrock Â· Nova Sonic (Audio)
    provider: bedrock
    litellm_params:
      model: bedrock/amazon.nova-sonic-v1:0
      region_name: us-east-1
    model_info:
      id: amazon.nova-sonic-v1:0
      mode: audio
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ pricing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # AWS price sheet (usâ€‘eastâ€‘1, Mayâ€‘2025):
    #   â–¸ $0.00006  per 1K  *text*  input tokens  (TTS prompt)
    #   â–¸ $0.0136   per 1K  *speech* output tokens (â‰ˆ perâ€‘second audio)
    # Convert to perâ€‘token & perâ€‘second:
    input_cost_per_token:  0.00000006    # $0.00006 / 1â€¯000
    output_cost_per_second: 0.0136       # Bedrock bills perâ€‘second for TTS audio
    max_tokens:        

  # ğŸ–¼ï¸ IMAGE â€‘ NovaÂ Canvas
  - model_name: Bedrock Â· Nova Canvas (Image)
    provider: bedrock
    litellm_params:
      model: bedrock/amazon.nova-canvas-v1:0
      region_name: us-east-1
    model_info:
      id: amazon.nova-canvas-v1:0
      mode: image_generation
    # AWS onâ€‘demand price: $0.018 per image generated
    output_cost_per_image: 0.018
    input_cost_per_pixel: 0              # prompt is free
    max_tokens:         

  # ğŸ¥ VIDEO â€‘ NovaÂ Reel
  - model_name: Bedrock Â· Nova Reel (Video)
    provider: bedrock
    litellm_params:
      model: bedrock/amazon.nova-reel-v1:0
      region_name: us-east-1
    model_info:
      id: amazon.nova-reel-v1:0
      mode: video             
    # AWS price: $0.08 per second of 720p 24â€¯fps video generated
    output_cost_per_second: 0.08
    max_tokens:


# --------------------------------------------
# ----------- Google Gemini Models -----------
# --------------------------------------------

  - model_name: "Google: gemini-1.5-flash"
    provider: google
    litellm_params:
      model: gemini/gemini-1.5-flash
    api_key: ${PP_GOOGLE_API_KEY}
    model_info:
      id: gemini-1.5-flash
      mode: completion
      input_cost_per_token: 0.00000035  # USD $0.35 per million tokens (input)
      output_cost_per_token: 0.00000150  # USD $1.50 per million tokens (output)
      max_tokens: 1048576  # 1 million tokens

  - model_name: "Google: gemini-2.0-flash"
    provider: google
    litellm_params:
      model: gemini/gemini-2.0-flash
    api_key: ${PP_GOOGLE_API_KEY}
    model_info:
      id: gemini-2.0-flash
      mode: completion
      input_cost_per_token: 0.00000035  # USD $0.35 per million tokens (input)
      output_cost_per_token: 0.00000150  # USD $1.50 per million tokens (output)
      max_tokens: 1048576  # 1 million tokens

  # - model_name: "Google: gemini-2.5-flash"
  #   provider: google
  #   litellm_params:
  #     model: gemini/gemini-2.5-flash
  #   api_key: ${PP_GOOGLE_API_KEY}
  #   model_info:
  #     id: gemini-2.5-flash
  #     mode: completion
  #     input_cost_per_token: 0.00000035  # USD $0.35 per million tokens (input)
  #     output_cost_per_token: 0.00000150  # USD $1.50 per million tokens (output)
  #     max_tokens: 1048576  # 1 million tokens

  # - model_name: "Google: gemini-1.5-pro"
  #   provider: google
  #   litellm_params:
  #     model: gemini/gemini-1.5-pro
  #   api_key: ${GEMINI_API_KEY}
  #   model_info:
  #     id: gemini-1.5-pro
  #     mode: completion
  #     input_cost_per_token: 0.00000125  # USD $1.25 per million tokens (input)
  #     output_cost_per_token: 0.00000500  # USD $5.00 per million tokens (output)
  #     max_tokens: 2097152  # 2 million tokens

  # - model_name: "Google: gemini-2.5-pro"
  #   provider: google
  #   litellm_params:
  #     model: gemini/gemini-2.5-pro
  #   api_key: ${PP_GOOGLE_API_KEY}
  #   model_info:
  #     id: gemini-2.5-pro
  #     mode: completion
  #     input_cost_per_token: 0.00000125  # USD $1.25 per million tokens (input)
  #     output_cost_per_token: 0.00000500  # USD $5.00 per million tokens (output)
  #     max_tokens: 2097152  # 2 million tokens